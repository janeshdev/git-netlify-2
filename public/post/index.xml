<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Janesh Devkota&#39;s Garden</title>
    <link>/post/</link>
    <description>Recent content in Posts on Janesh Devkota&#39;s Garden</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 12 Apr 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Tour de France Analysis</title>
      <link>/2020/04/tour-de-france-analysis/</link>
      <pubDate>Sun, 12 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/04/tour-de-france-analysis/</guid>
      <description>In this blog post, I am going to analyse the Tour de France TidyTuesday dataset. All tidy tuesdays dataset can be found on https://github.com/rfordatascience/tidytuesday. Tour de France datasets can be found on https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-04-07/readme.md
First of all let us download the data.
tdf_winners &amp;lt;- readr::read_csv(&amp;#39;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-04-07/tdf_winners.csv&amp;#39;) ## Parsed with column specification: ## cols( ## edition = col_double(), ## start_date = col_date(format = &amp;quot;&amp;quot;), ## winner_name = col_character(), ## winner_team = col_character(), ## distance = col_double(), ## time_overall = col_double(), ## time_margin = col_double(), ## stage_wins = col_double(), ## stages_led = col_double(), ## height = col_double(), ## weight = col_double(), ## age = col_double(), ## born = col_date(format = &amp;quot;&amp;quot;), ## died = col_date(format = &amp;quot;&amp;quot;), ## full_name = col_character(), ## nickname = col_character(), ## birth_town = col_character(), ## birth_country = col_character(), ## nationality = col_character() ## ) head(tdf_winners) ## # A tibble: 6 x 19 ## edition start_date winner_name winner_team distance time_overall time_margin ## &amp;lt;dbl&amp;gt; &amp;lt;date&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; ## 1 1 1903-07-01 Maurice Ga… La Françai… 2428 94.</description>
    </item>
    
    <item>
      <title>Regular Expressions in Python</title>
      <link>/2020/04/regular-expressions-in-python/</link>
      <pubDate>Sat, 11 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/04/regular-expressions-in-python/</guid>
      <description> In this post, we will look into how we can use text manipulation and using regular expression to do text manipulation.
Some of the common text tasks in python are as follows:
 Removing some text from the series or a list  test = [1, 2, &amp;#39;hello&amp;#39;] print(test[0]) ## 1 x &amp;lt;- c(12,2, 3, 4) print(x) ## [1] 12 2 3 4 </description>
    </item>
    
    <item>
      <title>Extracting water quality data from DataRetrieval Package</title>
      <link>/2018/02/extracting-water-quality-data-from-dataretrieval-package/</link>
      <pubDate>Mon, 19 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/02/extracting-water-quality-data-from-dataretrieval-package/</guid>
      <description>In this blog post, I will be showing some capabilities of dataRetrieval package by USGS to extract water quality data.
To install the dataRetrieval package use the following command:
devtools::install_github(repo = &amp;quot;USGS-R/dataRetrieval&amp;quot;) The main function I will be discussing is readWQPdata. The users can search the data using various options as shown below:
 bBox = Bounding box that uses the coordinates of lower left corner and upper right corner lat / long = lat / long will be specified by the user if they are interested to see if any data is available within radial distance.</description>
    </item>
    
    <item>
      <title>Spatial data and coordinate transformation in R</title>
      <link>/2017/12/spatial-analysis-and-coordinate-transformation-in-r/</link>
      <pubDate>Tue, 19 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/12/spatial-analysis-and-coordinate-transformation-in-r/</guid>
      <description>I come to these situations where I have to work with spatial datasets frequently. Sometimes the datasets is in lat-long format and sometimes on UTM (Universal transverse Mercator) coordinate or state plane coordinate system.
I extensively use EFDC (Environmental Fluid Dynamic Code) model to do environmental modeling and have to convert the data into UTM coordinate system. I had used CORPSCON in the past but as an R enthusiast I wanted to dig deeper in R and finad a way to do the transformation in R environment.</description>
    </item>
    
    <item>
      <title>2015 Earthquake in Nepal : Earthquake magnitude and Casualty Analysis</title>
      <link>/2017/12/2015-earthquake-in-nepal-data-analysis-and-implications/</link>
      <pubDate>Tue, 05 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/12/2015-earthquake-in-nepal-data-analysis-and-implications/</guid>
      <description>In this blogpost, I am going to take the earthquake data from April 2015 to May 2016 throughout the World. Then we will process the data in usable form and look at the data on Nepal. Later, we will also dive into the casualties from this devastating earthquake. We will look at how many people died, got injured from which district, using ggplot2, wordcloud and leaflet package.</description>
    </item>
    
  </channel>
</rss>